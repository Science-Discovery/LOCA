test_configs:
  - name: "gemini-2.5-pro"
    input_path: "problem_set/PHYBENCH_100/test.jsonl"
    output_path: "test_results/PHYBench/ToT/Gemini-2.5-pro/results.jsonl"
    scheme: "tot"
    temperature: 0.0
    models:
      generator: "gemini-2.5-pro"
    tot_options:
      evaluator_model: "gemini-2.5-pro"
      evaluator_temperature: 0.0
      max_depth: 4
      max_nodes: 15
      num_thoughts_per_node: 2
      prune_threshold: 4.0
    tools: []

  - name: "o3-2025-04-16"
    input_path: "problem_set/PHYBENCH_100/test.jsonl"
    output_path: "test_results/PHYBench/ToT/o3-2025-04-16/results.jsonl"
    scheme: "tot"
    temperature: 0.0
    models:
      generator: "o3-2025-04-16"
    tot_options:
      evaluator_model: "o3-2025-04-16"
      evaluator_temperature: 0.0
      max_depth: 4
      max_nodes: 15
      num_thoughts_per_node: 2
      prune_threshold: 4.0
    tools: []

  - name: "gpt-5"
    input_path: "problem_set/PHYBENCH_100/test.jsonl"
    output_path: "test_results/PHYBench/ToT/GPT-5/results.jsonl"
    scheme: "tot"
    temperature: 0.0
    models:
      generator: "gpt-5"
    tot_options:
      evaluator_model: "gpt-5"
      evaluator_temperature: 0.0
      max_depth: 4
      max_nodes: 15
      num_thoughts_per_node: 2
      prune_threshold: 4.0
    tools: []

  - name: "deepseek-r1-250528"
    input_path: "problem_set/PHYBENCH_100/test.jsonl"
    output_path: "test_results/PHYBench/ToT/DeepSeek-r1-250528/results.jsonl"
    scheme: "tot"
    temperature: 0.0
    models:
      generator: "deepseek-r1-250528"
    tot_options:
      evaluator_model: "deepseek-r1-250528"
      evaluator_temperature: 0.0
      max_depth: 4
      max_nodes: 15
      num_thoughts_per_node: 2
      prune_threshold: 4.0
    tools: []

global_settings:
  concurrent_limit: 10
  aux_dir_base: ".aux"
