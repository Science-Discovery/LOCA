test_configs:
- name: gemini-2.5-pro
  input_path: problem_set/ABench/test.jsonl
  output_path: test_results/ABench/ToT/Gemini-2.5-pro/results.jsonl
  scheme: tot
  temperature: 0.0
  models:
    generator: gemini-2.5-pro
  tot_options:
    evaluator_model: gemini-2.5-pro
    evaluator_temperature: 0.0
    max_depth: 4
    max_nodes: 15
    num_thoughts_per_node: 2
    prune_threshold: 4.0
  tools: []
global_settings:
  concurrent_limit: 10
  aux_dir_base: .aux
